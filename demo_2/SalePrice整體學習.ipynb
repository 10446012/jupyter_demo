{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities    ...     PoolArea PoolQC Fence MiscFeature MiscVal  \\\n",
       "0         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
       "1         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
       "2         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
       "3         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
       "4         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
       "\n",
       "  MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0      2   2008        WD         Normal     208500  \n",
       "1      5   2007        WD         Normal     181500  \n",
       "2      9   2008        WD         Normal     223500  \n",
       "3      2   2006        WD        Abnorml     140000  \n",
       "4     12   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#invite people for the Kaggle party\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "from sklearn import ensemble, tree, linear_model\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.utils import shuffle\n",
    "import xgboost as xgb \n",
    "\n",
    "\n",
    "plt.rcParams['font.family']='DFKai-SB' #顯示中文(for Win10)\n",
    "plt.rcParams['axes.unicode_minus']=False #正常顯示負號\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x = train['GrLivArea'], y = train['SalePrice'])\n",
    "plt.ylabel('SalePrice', fontsize=13)\n",
    "plt.xlabel('GrLivArea', fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deleting outliers\n",
    "train = train.drop(train[(train['GrLivArea']>4000) & (train['SalePrice']<300000)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prints R2 and RMSE scores\n",
    "def get_score(prediction, lables):    \n",
    "    print('R2: {}'.format(r2_score(prediction, lables)))\n",
    "    print('RMSE: {}'.format(np.sqrt(mean_squared_error(prediction, lables))))\n",
    "\n",
    "# Shows scores for train and validation sets    \n",
    "def train_test(estimator, x_trn, x_tst, y_trn, y_tst):\n",
    "    prediction_train = estimator.predict(x_trn)\n",
    "    # Printing estimator\n",
    "    print(estimator)\n",
    "    # Printing train scores\n",
    "    get_score(prediction_train, y_trn)\n",
    "    prediction_test = estimator.predict(x_tst)\n",
    "    # Printing test scores\n",
    "    print(\"Test\")\n",
    "    get_score(prediction_test, y_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting to features and lables and deleting variable I don't need\n",
    "train_labels = train.pop('SalePrice')\n",
    "features = pd.concat([train, test], keys=['train', 'test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities      ...       ScreenPorch PoolArea PoolQC Fence  \\\n",
       "0         Lvl    AllPub      ...                 0        0    NaN   NaN   \n",
       "1         Lvl    AllPub      ...                 0        0    NaN   NaN   \n",
       "2         Lvl    AllPub      ...                 0        0    NaN   NaN   \n",
       "3         Lvl    AllPub      ...                 0        0    NaN   NaN   \n",
       "4         Lvl    AllPub      ...                 0        0    NaN   NaN   \n",
       "\n",
       "  MiscFeature MiscVal MoSold  YrSold  SaleType  SaleCondition  \n",
       "0         NaN       0      2    2008        WD         Normal  \n",
       "1         NaN       0      5    2007        WD         Normal  \n",
       "2         NaN       0      9    2008        WD         Normal  \n",
       "3         NaN       0      2    2006        WD        Abnorml  \n",
       "4         NaN       0     12    2008        WD         Normal  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PoolQC</th>\n",
       "      <td>1452</td>\n",
       "      <td>0.995885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MiscFeature</th>\n",
       "      <td>1404</td>\n",
       "      <td>0.962963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alley</th>\n",
       "      <td>1367</td>\n",
       "      <td>0.937586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fence</th>\n",
       "      <td>1177</td>\n",
       "      <td>0.807270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FireplaceQu</th>\n",
       "      <td>690</td>\n",
       "      <td>0.473251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LotFrontage</th>\n",
       "      <td>259</td>\n",
       "      <td>0.177641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageCond</th>\n",
       "      <td>81</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageType</th>\n",
       "      <td>81</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <td>81</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageFinish</th>\n",
       "      <td>81</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageQual</th>\n",
       "      <td>81</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtExposure</th>\n",
       "      <td>38</td>\n",
       "      <td>0.026063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinType2</th>\n",
       "      <td>38</td>\n",
       "      <td>0.026063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtCond</th>\n",
       "      <td>37</td>\n",
       "      <td>0.025377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtQual</th>\n",
       "      <td>37</td>\n",
       "      <td>0.025377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinType1</th>\n",
       "      <td>37</td>\n",
       "      <td>0.025377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MasVnrArea</th>\n",
       "      <td>8</td>\n",
       "      <td>0.005487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MasVnrType</th>\n",
       "      <td>8</td>\n",
       "      <td>0.005487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Electrical</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Utilities</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Total   Percent\n",
       "PoolQC         1452  0.995885\n",
       "MiscFeature    1404  0.962963\n",
       "Alley          1367  0.937586\n",
       "Fence          1177  0.807270\n",
       "FireplaceQu     690  0.473251\n",
       "LotFrontage     259  0.177641\n",
       "GarageCond       81  0.055556\n",
       "GarageType       81  0.055556\n",
       "GarageYrBlt      81  0.055556\n",
       "GarageFinish     81  0.055556\n",
       "GarageQual       81  0.055556\n",
       "BsmtExposure     38  0.026063\n",
       "BsmtFinType2     38  0.026063\n",
       "BsmtCond         37  0.025377\n",
       "BsmtQual         37  0.025377\n",
       "BsmtFinType1     37  0.025377\n",
       "MasVnrArea        8  0.005487\n",
       "MasVnrType        8  0.005487\n",
       "Electrical        1  0.000686\n",
       "Utilities         0  0.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#missing data\n",
    "total = train.isnull().sum().sort_values(ascending=False)\n",
    "percent = (train.isnull().sum()/train.isnull().count()).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "missing_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting to features and lables and deleting variable I don't need\n",
    "\n",
    "# I decided to get rid of features that have more than half of missing information or do not correlate to SalePrice\n",
    "features.drop(['Utilities', 'RoofMatl', 'MasVnrArea', 'Heating', 'LowQualFinSF', 'WoodDeckSF',\n",
    "               'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal'],\n",
    "              axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities      ...       ScreenPorch PoolArea PoolQC Fence  \\\n",
       "0         Lvl    AllPub      ...                 0        0    NaN   NaN   \n",
       "1         Lvl    AllPub      ...                 0        0    NaN   NaN   \n",
       "2         Lvl    AllPub      ...                 0        0    NaN   NaN   \n",
       "3         Lvl    AllPub      ...                 0        0    NaN   NaN   \n",
       "4         Lvl    AllPub      ...                 0        0    NaN   NaN   \n",
       "\n",
       "  MiscFeature MiscVal MoSold  YrSold  SaleType  SaleCondition  \n",
       "0         NaN       0      2    2008        WD         Normal  \n",
       "1         NaN       0      5    2007        WD         Normal  \n",
       "2         NaN       0      9    2008        WD         Normal  \n",
       "3         NaN       0      2    2006        WD        Abnorml  \n",
       "4         NaN       0     12    2008        WD         Normal  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features[\"PoolQC\"] = features[\"PoolQC\"].fillna(\"None\")\n",
    "features[\"MiscFeature\"] = features[\"MiscFeature\"].fillna(\"None\")\n",
    "features[\"Fence\"] = features[\"Fence\"].fillna(\"None\")\n",
    "\n",
    "for col in ('GarageYrBlt', 'GarageArea', 'GarageCond'):\n",
    "    features[col] = features[col].fillna(0)\n",
    "\n",
    "for col in ('BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'BsmtFullBath', 'BsmtHalfBath'):\n",
    "    features[col] = features[col].fillna(0)\n",
    "    \n",
    "features[\"Functional\"] = features[\"Functional\"].fillna(\"Typ\")\n",
    "     \n",
    "# MSSubClass as str\n",
    "features['MSSubClass'] = features['MSSubClass'].astype(str)\n",
    "\n",
    "# MSZoning NA in pred. filling with most popular values\n",
    "features['MSZoning'] = features['MSZoning'].fillna(features['MSZoning'].mode()[0])\n",
    "\n",
    "# LotFrontage  NA in all. I suppose NA means 0\n",
    "features['LotFrontage'] = features['LotFrontage'].fillna(features['LotFrontage'].mean())\n",
    "\n",
    "# Alley  NA in all. NA means no access\n",
    "features['Alley'] = features['Alley'].fillna('NOACCESS')\n",
    "\n",
    "# Converting OverallCond to str\n",
    "features.OverallCond = features.OverallCond.astype(str)\n",
    "\n",
    "# MasVnrType NA in all. filling with most popular values\n",
    "features['MasVnrType'] = features['MasVnrType'].fillna(features['MasVnrType'].mode()[0])\n",
    "\n",
    "# BsmtQual, BsmtCond, BsmtExposure, BsmtFinType1, BsmtFinType2\n",
    "# NA in all. NA means No basement\n",
    "for col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):\n",
    "    features[col] = features[col].fillna('NoBSMT')\n",
    "\n",
    "# TotalBsmtSF  NA in pred. I suppose NA means 0\n",
    "features['TotalBsmtSF'] = features['TotalBsmtSF'].fillna(0)\n",
    "\n",
    "\n",
    "# Electrical NA in pred. filling with most popular values\n",
    "features['Electrical'] = features['Electrical'].fillna(features['Electrical'].mode()[0])\n",
    "\n",
    "# KitchenAbvGr to categorical\n",
    "features['KitchenAbvGr'] = features['KitchenAbvGr'].astype(str)\n",
    "\n",
    "# KitchenQual NA in pred. filling with most popular values\n",
    "features['KitchenQual'] = features['KitchenQual'].fillna(features['KitchenQual'].mode()[0])\n",
    "\n",
    "# FireplaceQu  NA in all. NA means No Fireplace\n",
    "features['FireplaceQu'] = features['FireplaceQu'].fillna('NoFP')\n",
    "\n",
    "# GarageType, GarageFinish, GarageQual  NA in all. NA means No Garage\n",
    "for col in ('GarageType', 'GarageFinish', 'GarageQual'):\n",
    "    features[col] = features[col].fillna('NoGRG')\n",
    "\n",
    "# GarageCars  NA in pred. I suppose NA means 0\n",
    "features['GarageCars'] = features['GarageCars'].fillna(0.0)\n",
    "\n",
    "# SaleType NA in pred. filling with most popular values\n",
    "features['SaleType'] = features['SaleType'].fillna(features['SaleType'].mode()[0])\n",
    "\n",
    "# Year and Month to categorical\n",
    "features['YrSold'] = features['YrSold'].astype(str)\n",
    "features['MoSold'] = features['MoSold'].astype(str)\n",
    "\n",
    "# Adding total sqfootage feature and removing Basement, 1st and 2nd floor features\n",
    "features['TotalSF'] = features['TotalBsmtSF'] + features['1stFlrSF'] + features['2ndFlrSF']\n",
    "features.drop(['TotalBsmtSF', '1stFlrSF', '2ndFlrSF'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Skew in numerical features: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Skew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LotArea</th>\n",
       "      <td>13.109495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <td>4.144503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <td>3.929996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LotFrontage</th>\n",
       "      <td>1.228305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GrLivArea</th>\n",
       "      <td>1.068750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalSF</th>\n",
       "      <td>1.009157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <td>0.980645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <td>0.919688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <td>0.749232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fireplaces</th>\n",
       "      <td>0.725278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Skew\n",
       "LotArea       13.109495\n",
       "BsmtFinSF2     4.144503\n",
       "BsmtHalfBath   3.929996\n",
       "LotFrontage    1.228305\n",
       "GrLivArea      1.068750\n",
       "TotalSF        1.009157\n",
       "BsmtFinSF1     0.980645\n",
       "BsmtUnfSF      0.919688\n",
       "TotRmsAbvGrd   0.749232\n",
       "Fireplaces     0.725278"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "from scipy.stats import norm, skew #for some statistics\n",
    "numeric_feats = features.dtypes[features.dtypes != \"object\"].index\n",
    "\n",
    "# Check the skew of all numerical features\n",
    "skewed_feats = features[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\n",
    "print(\"\\nSkew in numerical features: \\n\")\n",
    "skewness = pd.DataFrame({'Skew' :skewed_feats})\n",
    "skewness.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 21 skewed numerical features to Box Cox transform\n"
     ]
    }
   ],
   "source": [
    "skewness = skewness[abs(skewness) > 0.75]\n",
    "print(\"There are {} skewed numerical features to Box Cox transform\".format(skewness.shape[0]))\n",
    "\n",
    "from scipy.special import boxcox1p\n",
    "skewed_features = skewness.index\n",
    "lam = 0.15\n",
    "for feat in skewed_features:\n",
    "    #features[feat] += 1\n",
    "    features[feat] = boxcox1p(features[feat], lam)\n",
    "    \n",
    "# features[skewed_features] = np.log1p(features[skewed_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Standardizing numeric features\n",
    "numeric_features = train.loc[:,['LotFrontage', 'LotArea', 'GrLivArea', 'TotalSF']]\n",
    "numeric_features_standardized = (numeric_features - numeric_features.mean())/numeric_features.std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Dummies from Condition1 and Condition2\n",
    "conditions = set([x for x in features['Condition1']] + [x for x in features['Condition2']])\n",
    "dummies = pd.DataFrame(data=np.zeros((len(features.index), len(conditions))),\n",
    "                       index=features.index, columns=conditions)\n",
    "for i, cond in enumerate(zip(features['Condition1'], features['Condition2'])):\n",
    "    dummies.ix[i, cond] = 1\n",
    "features = pd.concat([features, dummies.add_prefix('Condition_')], axis=1)\n",
    "features.drop(['Condition1', 'Condition2'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Dummies from Exterior1st and Exterior2nd\n",
    "exteriors = set([x for x in features['Exterior1st']] + [x for x in features['Exterior2nd']])\n",
    "dummies = pd.DataFrame(data=np.zeros((len(features.index), len(exteriors))),\n",
    "                       index=features.index, columns=exteriors)\n",
    "for i, ext in enumerate(zip(features['Exterior1st'], features['Exterior2nd'])):\n",
    "    dummies.ix[i, ext] = 1\n",
    "features = pd.concat([features, dummies.add_prefix('Exterior_')], axis=1)\n",
    "features.drop(['Exterior1st', 'Exterior2nd'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Dummies from all other categorical vars\n",
    "for col in features.dtypes[features.dtypes == 'object'].index:\n",
    "    for_dummy = features.pop(col)\n",
    "    features = pd.concat([features, pd.get_dummies(for_dummy, prefix=col)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Copying features\n",
    "features_standardized = features.copy()\n",
    "\n",
    "### Replacing numeric features by standardized values\n",
    "features_standardized.update(numeric_features_standardized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Splitting features\n",
    "train_features = features.loc['train'].drop('Id', axis=1).select_dtypes(include=[np.number]).values\n",
    "test_features = features.loc['test'].drop('Id', axis=1).select_dtypes(include=[np.number]).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.83132789, 19.21218231,  2.44026838, ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [ 6.22121363, 19.71220478,  2.25967379, ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [ 5.91494002, 20.34724091,  2.44026838, ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 5.85955121, 19.47634523,  2.44026838, ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [ 5.91494002, 19.76017576,  2.05564154, ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [ 6.0986261 , 19.84906344,  2.05564154, ...,  0.        ,\n",
       "         1.        ,  0.        ]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Splitting standardized features\n",
    "train_features_st = features_standardized.loc['train'].drop('Id', axis=1).select_dtypes(include=[np.number]).values\n",
    "test_features_st = features_standardized.loc['test'].drop('Id', axis=1).select_dtypes(include=[np.number]).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Shuffling train sets\n",
    "train_features_st, train_features, train_labels = shuffle(train_features_st, train_features, train_labels, random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Splitting\n",
    "x_train, x_test, y_train, y_test = train_test_split(train_features, train_labels, test_size=0.1, random_state=200)\n",
    "x_train_st, x_test_st, y_train_st, y_test_st = train_test_split(train_features_st, train_labels, test_size=0.1, random_state=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prints R2 and RMSE scores\n",
    "def get_score(prediction, lables):    \n",
    "    print('R2: {}'.format(r2_score(prediction, lables)))\n",
    "    print('RMSE: {}'.format(np.sqrt(mean_squared_error(prediction, lables))))\n",
    "\n",
    "# Shows scores for train and validation sets    \n",
    "def train_test(estimator, x_trn, x_tst, y_trn, y_tst):\n",
    "    prediction_train = estimator.predict(x_trn)\n",
    "    # Printing estimator\n",
    "    print(estimator)\n",
    "    # Printing train scores\n",
    "    get_score(prediction_train, y_trn)\n",
    "    prediction_test = estimator.predict(x_tst)\n",
    "    # Printing test scores\n",
    "    print(\"Test\")\n",
    "    get_score(prediction_test, y_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "sc.fit(x_train_st)\n",
    "train_features = sc.transform(x_train_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "train_labels = np.log(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)\n",
      "R2: 0.9229197417394146\n",
      "RMSE: 20939.95489683402\n",
      "Test\n",
      "R2: 0.8138043269427164\n",
      "RMSE: 34390.67180086752\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(x_train_st, y_train_st)\n",
    "train_test(lr, x_train_st, x_test_st, y_train_st, y_test_st)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.9041 (0.0156)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(lr, train_features_st, train_labels, cv=5)\n",
    "print(\"Accuracy score: {:.4f} ({:.4f})\\n\".format(scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "          metric_params=None, n_jobs=1, n_neighbors=2, p=2,\n",
      "          weights='uniform')\n",
      "R2: 0.9177209430160823\n",
      "RMSE: 20545.69452946701\n",
      "Test\n",
      "R2: 0.7191268858527253\n",
      "RMSE: 38427.50048135922\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "knnr = KNeighborsRegressor(n_neighbors=2,weights='uniform')\n",
    "knnr.fit(x_train_st, y_train_st)\n",
    "train_test(knnr, x_train_st, x_test_st, y_train_st, y_test_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.7632 (0.0219)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(knnr, train_features_st, train_labels, cv=5)\n",
    "print(\"Accuracy score: {:.4f} ({:.4f})\\n\".format(scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeRegressor(criterion='mse', max_depth=5, max_features=None,\n",
      "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "           min_impurity_split=None, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           presort=False, random_state=None, splitter='best')\n",
      "R2: 0.8694350820281075\n",
      "RMSE: 26600.738380385363\n",
      "Test\n",
      "R2: 0.8102090762560685\n",
      "RMSE: 35342.353534041016\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "dtr = DecisionTreeRegressor(max_depth=5)\n",
    "dtr.fit(x_train_st, y_train_st)\n",
    "train_test(dtr, x_train_st, x_test_st, y_train_st, y_test_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.7902 (0.0154)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(dtr, train_features_st, train_labels, cv=5)\n",
    "print(\"Accuracy score: {:.4f} ({:.4f})\\n\".format(scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "             learning_rate=0.05, loss='huber', max_depth=3,\n",
      "             max_features='sqrt', max_leaf_nodes=None,\n",
      "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "             min_samples_leaf=15, min_samples_split=10,\n",
      "             min_weight_fraction_leaf=0.0, n_estimators=3000,\n",
      "             presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "             warm_start=False)\n",
      "R2: 0.9748348257665327\n",
      "RMSE: 11991.127083277961\n",
      "Test\n",
      "R2: 0.8954258087311171\n",
      "RMSE: 25239.088967357726\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "GBest = ensemble.GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05, max_depth=3, max_features='sqrt',\n",
    "                                               min_samples_leaf=15, min_samples_split=10, loss='huber').fit(x_train, y_train)\n",
    "train_test(GBest, x_train_st, x_test_st, y_train_st, y_test_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.9126 (0.0161)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(GBest, train_features_st, train_labels, cv=5)\n",
    "print(\"Accuracy score: {:.4f} ({:.4f})\\n\".format(scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNetCV(alphas=[0.0001, 0.0005, 0.001, 0.01, 0.1, 1, 10], copy_X=True,\n",
      "       cv=None, eps=0.001, fit_intercept=True,\n",
      "       l1_ratio=[0.01, 0.1, 0.5, 0.9, 0.99], max_iter=5000, n_alphas=100,\n",
      "       n_jobs=1, normalize=False, positive=False, precompute='auto',\n",
      "       random_state=None, selection='cyclic', tol=0.0001, verbose=0)\n",
      "R2: 0.9029166246658468\n",
      "RMSE: 22912.481401523335\n",
      "Test\n",
      "R2: 0.8166981057368363\n",
      "RMSE: 32477.77363560866\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "ENSTest = linear_model.ElasticNetCV(alphas=[0.0001, 0.0005, 0.001, 0.01, 0.1, 1, 10], l1_ratio=[.01, .1, .5, .9, .99], max_iter=5000).fit(x_train_st, y_train_st)\n",
    "train_test(ENSTest, x_train_st, x_test_st, y_train_st, y_test_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.9182 (0.0109)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(ENSTest, train_features_st, train_labels, cv=5)\n",
    "print(\"Accuracy score: {:.4f} ({:.4f})\\n\".format(scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=-1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
      "R2: 0.9844083830134267\n",
      "RMSE: 9348.304469691033\n",
      "Test\n",
      "R2: 0.83743697781047\n",
      "RMSE: 29763.050519235927\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rfc = RandomForestRegressor(n_estimators=500, n_jobs=-1)\n",
    "rfc.fit(x_train_st, y_train_st)\n",
    "train_test(rfc, x_train_st, x_test_st, y_train_st, y_test_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.8832 (0.0201)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(rfc, train_features_st, train_labels, cv=5)\n",
    "print(\"Accuracy score: {:.4f} ({:.4f})\\n\".format(scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "         n_estimators=500, random_state=None)\n",
      "R2: 0.8711999587229483\n",
      "RMSE: 25126.426810553996\n",
      "Test\n",
      "R2: 0.8010422268089574\n",
      "RMSE: 31960.692213284805\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "ada = AdaBoostRegressor(n_estimators=500)\n",
    "ada.fit(x_train_st, y_train_st)\n",
    "train_test(ada, x_train_st, x_test_st, y_train_st, y_test_st)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.8186 (0.0107)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(ada, train_features_st, train_labels, cv=5)\n",
    "print(\"Accuracy score: {:.4f} ({:.4f})\\n\".format(scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingRegressor(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=200, n_jobs=1, oob_score=True, random_state=None,\n",
      "         verbose=0, warm_start=False)\n",
      "R2: 0.984630845550848\n",
      "RMSE: 9291.636550179575\n",
      "Test\n",
      "R2: 0.8469169811065358\n",
      "RMSE: 29156.74217277074\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "bagc = BaggingRegressor(n_estimators=200, oob_score=True)\n",
    "\n",
    "bagc.fit(x_train_st, y_train_st)\n",
    "train_test(bagc, x_train_st, x_test_st, y_train_st, y_test_st)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.8832 (0.0216)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(bagc, train_features_st, train_labels, cv=5)\n",
    "print(\"Accuracy score: {:.4f} ({:.4f})\\n\".format(scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "mingw_path = 'C:\\\\Program Files\\\\mingw-w64\\\\x86_64-5.3.0-posix-seh-rt_v5-rev2\\\\mingw64\\\\bin'\n",
    "os.environ['PATH'] = mingw_path + ';' + os.environ['PATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.05, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "R2: 0.9389267436577965\n",
      "RMSE: 17948.692650154557\n",
      "Test\n",
      "R2: 0.8765820992672336\n",
      "RMSE: 26517.55619433926\n"
     ]
    }
   ],
   "source": [
    "model_xgb = xgb.XGBRegressor(learning_rate=0.05, max_depth=3)\n",
    "\n",
    "model_xgb.fit(x_train_st, y_train_st)\n",
    "train_test(model_xgb, x_train_st, x_test_st, y_train_st, y_test_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.8486 (0.0207)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(model_xgb, train_features_st, train_labels, cv=5)\n",
    "print(\"Accuracy score: {:.4f} ({:.4f})\\n\".format(scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "class AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "        \n",
    "    # we define clones of the original models to fit the data in\n",
    "    def fit(self, X, y):\n",
    "        self.models_ = [clone(x) for x in self.models]\n",
    "        \n",
    "        # Train cloned base models\n",
    "        for model in self.models_:\n",
    "            model.fit(X, y)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    #Now we do the predictions for cloned models and average them\n",
    "    def predict(self, X):\n",
    "        predictions = np.column_stack([\n",
    "            model.predict(X) for model in self.models_\n",
    "        ])\n",
    "        return np.mean(predictions, axis=1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "averaged_models = AveragingModels(models = (model_xgb, rfc, bagc, GBest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, base_models, meta_model, n_folds=5):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.n_folds = n_folds\n",
    "   \n",
    "    # We again fit the data on clones of the original models\n",
    "    def fit(self, X, y):\n",
    "        self.base_models_ = [list() for x in self.base_models]\n",
    "        self.meta_model_ = clone(self.meta_model)\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=156)\n",
    "        \n",
    "        # Train cloned base models then create out-of-fold predictions\n",
    "        # that are needed to train the cloned meta-model\n",
    "        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        for i, model in enumerate(self.base_models):\n",
    "            for train_index, holdout_index in kfold.split(X, y):\n",
    "                instance = clone(model)\n",
    "                self.base_models_[i].append(instance)\n",
    "                instance.fit(X[train_index], y[train_index])\n",
    "                y_pred = instance.predict(X[holdout_index])\n",
    "                out_of_fold_predictions[holdout_index, i] = y_pred\n",
    "                \n",
    "        # Now train the cloned  meta-model using the out-of-fold predictions as new feature\n",
    "        self.meta_model_.fit(out_of_fold_predictions, y)\n",
    "        return self\n",
    "   \n",
    "    #Do the predictions of all base models on the test data and use the averaged predictions as \n",
    "    #meta-features for the final prediction which is done by the meta-model\n",
    "    def predict(self, X):\n",
    "        meta_features = np.column_stack([\n",
    "            np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n",
    "            for base_models in self.base_models_ ])\n",
    "        return self.meta_model_.predict(meta_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacked_averaged_models = StackingAveragedModels(base_models = (model_xgb, rfc, bagc, GBest), meta_model = ENSTest)\n",
    "stacked_averaged_models = StackingAveragedModels(base_models = (model_xgb, rfc, bagc),\n",
    "                                                 meta_model = GBest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def rmsle(y, y_pred):\n",
    "#    return np.sqrt(mean_squared_error(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "stacked_averaged_models.fit(train_features_st, train_labels.values)\n",
    "stacked_train_pred = stacked_averaged_models.predict(train_features_st)\n",
    "stacked_pred = np.expm1(stacked_averaged_models.predict(test_features_st))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_test_normalized = sc.transform(test_features_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENST_model = ENSTest.fit(train_features_st, train_labels)\n",
    "GB_model = GBest.fit(train_features_st, train_labels)\n",
    "rfc_model = rfc.fit(train_features_st, train_labels)\n",
    "xgboost_model = model_xgb.fit(train_features_st, train_labels)\n",
    "ensemble = stacked_pred\n",
    "Finalscore = ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# xgb_score = np.exp(xgboost_model.predict(test_features_st)) \n",
    "# Finalscore = (stacked_pred*0.60 + xgb_score*0.40) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to file to make a submission\n",
    "\n",
    "# solution = pd.DataFrame({\"Id\":test.Id, \"SalePrice\":Final_labels}, columns=['Id', 'SalePrice'])\n",
    "solution = pd.DataFrame({\"Id\":test.Id, \"SalePrice\":Finalscore}, columns=['Id', 'SalePrice'])\n",
    "solution.to_csv(\"ensemble.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
